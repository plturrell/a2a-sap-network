version: '3.8'

services:
  # Elasticsearch for log storage
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: a2a-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
      - cluster.name=a2a-logs
      - node.name=a2a-es-node
      - bootstrap.memory_lock=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
      - ./logging/elasticsearch/config:/usr/share/elasticsearch/config:ro
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - a2a-logging
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Logstash for log processing and transformation
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: a2a-logstash
    restart: unless-stopped
    environment:
      - xpack.monitoring.enabled=false
      - "LS_JAVA_OPTS=-Xms1g -Xmx1g"
    volumes:
      - ./logging/logstash/config:/usr/share/logstash/config:ro
      - ./logging/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - logstash-data:/usr/share/logstash/data
    ports:
      - "5044:5044"  # Beats input
      - "5000:5000"  # TCP input
      - "9600:9600"  # HTTP API
    networks:
      - a2a-logging
    depends_on:
      elasticsearch:
        condition: service_healthy

  # Kibana for log visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: a2a-kibana
    restart: unless-stopped
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - server.name=a2a-kibana
      - server.host=0.0.0.0
      - xpack.security.enabled=false
      - xpack.encryptedSavedObjects.encryptionKey=a2a-kibana-encryption-key-32-chars
    volumes:
      - ./logging/kibana/config:/usr/share/kibana/config:ro
      - kibana-data:/usr/share/kibana/data
    ports:
      - "5601:5601"
    networks:
      - a2a-logging
    depends_on:
      - elasticsearch
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5601/api/status"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Filebeat for log collection from containers
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: a2a-filebeat
    restart: unless-stopped
    user: root
    command: filebeat -e -strict.perms=false
    volumes:
      - ./logging/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/log:/var/log:ro
      - filebeat-data:/usr/share/filebeat/data
    networks:
      - a2a-logging
    depends_on:
      - logstash
    environment:
      - LOGSTASH_HOST=logstash:5044
      - ELASTICSEARCH_HOST=elasticsearch:9200

  # Fluent Bit as alternative lightweight log collector
  fluent-bit:
    image: fluent/fluent-bit:2.2
    container_name: a2a-fluent-bit
    restart: unless-stopped
    volumes:
      - ./logging/fluent-bit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - ./logging/fluent-bit/parsers.conf:/fluent-bit/etc/parsers.conf:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/log:/var/log:ro
    networks:
      - a2a-logging
    depends_on:
      - elasticsearch
    environment:
      - FLB_ES_HOST=elasticsearch
      - FLB_ES_PORT=9200

  # Loki for lightweight log aggregation (alternative to ELK)
  loki:
    image: grafana/loki:2.9.0
    container_name: a2a-loki
    restart: unless-stopped
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - "3100:3100"
    volumes:
      - ./logging/loki/local-config.yaml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    networks:
      - a2a-logging
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Promtail for log collection to Loki
  promtail:
    image: grafana/promtail:2.9.0
    container_name: a2a-promtail
    restart: unless-stopped
    command: -config.file=/etc/promtail/config.yml
    volumes:
      - ./logging/promtail/config.yml:/etc/promtail/config.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/log:/var/log:ro
      - promtail-data:/promtail
    networks:
      - a2a-logging
    depends_on:
      - loki

  # Vector for high-performance log processing
  vector:
    image: timberio/vector:0.34.0-alpine
    container_name: a2a-vector
    restart: unless-stopped
    volumes:
      - ./logging/vector/vector.toml:/etc/vector/vector.toml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - vector-data:/var/lib/vector
    networks:
      - a2a-logging
    depends_on:
      - elasticsearch
      - loki
    ports:
      - "8686:8686"  # Vector API

  # Log rotation and cleanup service
  logrotate:
    image: alpine:3.18
    container_name: a2a-logrotate
    restart: unless-stopped
    volumes:
      - /var/log:/var/log
      - ./logging/logrotate/logrotate.conf:/etc/logrotate.conf:ro
      - ./logging/logrotate/scripts:/scripts:ro
    command: sh -c "while true; do /usr/sbin/logrotate /etc/logrotate.conf --verbose; sleep 3600; done"
    networks:
      - a2a-logging

volumes:
  elasticsearch-data:
    driver: local
  logstash-data:
    driver: local
  kibana-data:
    driver: local
  filebeat-data:
    driver: local
  loki-data:
    driver: local
  promtail-data:
    driver: local
  vector-data:
    driver: local

networks:
  a2a-logging:
    driver: bridge
    external: false

# Extend main A2A network to include logging
  a2a-network:
    external: true