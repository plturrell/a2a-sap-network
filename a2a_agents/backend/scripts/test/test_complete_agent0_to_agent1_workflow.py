#!/usr/bin/env python3
"""
Comprehensive Test Suite for Agent 0 â†’ Agent 1 Workflow
Tests BPMN compliance, specifications, and all claimed features including:
- Dublin Core metadata extraction and quality assessment
- SHA256 hashing and referential integrity checks
- ORD Registry registration and discovery
- End-to-end workflow execution
- Data lineage tracking
"""

import requests
import json
import time
import hashlib
import pandas as pd
import os
from datetime import datetime
from typing import Dict, List, Any, Optional


class Agent0ToAgent1WorkflowTester:
    """Comprehensive tester for Agent 0 â†’ Agent 1 workflow"""
    
    def __init__(self):
        self.base_url = "http://localhost:8000"
        self.agent0_url = "http://localhost:8002"  # Agent 0 URL
        self.agent1_url = "http://localhost:8001"  # Agent 1 URL
        self.ord_registry_url = f"{self.base_url}/api/v1/ord"
        self.a2a_registry_url = f"{self.base_url}/api/v1/a2a"
        
        self.test_results = {
            "overall_status": "pending",
            "test_sections": {},
            "compliance_report": {},
            "feature_verification": {},
            "gaps_identified": []
        }
        
        self.raw_data_path = "/Users/apple/projects/finsight_cib/data/raw"
        
    def run_complete_test_suite(self):
        """Run the complete test suite"""
        print("=" * 80)
        print("COMPREHENSIVE AGENT 0 â†’ AGENT 1 WORKFLOW TEST SUITE")
        print("=" * 80)
        print(f"Start Time: {datetime.now().isoformat()}")
        print()
        
        try:
            # Test 1: Environment Setup and Service Health
            self.test_environment_setup()
            
            # Test 2: Raw Data Analysis and Integrity
            self.test_raw_data_integrity()
            
            # Test 3: Agent 0 Capabilities
            self.test_agent0_capabilities()
            
            # Test 4: ORD Registry Integration
            self.test_ord_registry_integration()
            
            # Test 5: Agent 1 Discovery and Processing
            self.test_agent1_discovery()
            
            # Test 6: End-to-End Workflow
            self.test_end_to_end_workflow()
            
            # Test 7: Dublin Core Compliance
            self.test_dublin_core_compliance()
            
            # Test 8: Data Integrity and Lineage
            self.test_data_integrity_features()
            
            # Generate Final Report
            self.generate_compliance_report()
            
            self.test_results["overall_status"] = "completed"
            
        except Exception as e:
            print(f"âŒ Test suite failed with error: {str(e)}")
            self.test_results["overall_status"] = "failed"
            self.test_results["error"] = str(e)
        
        print("\n" + "=" * 80)
        print("TEST SUITE COMPLETED")
        print("=" * 80)
        
        return self.test_results
    
    def test_environment_setup(self):
        """Test 1: Environment Setup and Service Health"""
        print("ğŸ”§ Test 1: Environment Setup and Service Health")
        print("-" * 50)
        
        results = {}
        
        # Check main backend
        try:
            response = requests.get(f"{self.base_url}/health", timeout=5)
            if response.status_code == 200:
                results["main_backend"] = {"status": "healthy", "response": response.json()}
                print("âœ… Main backend is healthy")
            else:
                results["main_backend"] = {"status": "unhealthy", "code": response.status_code}
                print(f"âŒ Main backend unhealthy: {response.status_code}")
        except Exception as e:
            results["main_backend"] = {"status": "error", "error": str(e)}
            print(f"âŒ Main backend error: {str(e)}")
        
        # Check ORD Registry
        try:
            response = requests.get(f"{self.ord_registry_url}/health", timeout=5)
            if response.status_code == 200:
                results["ord_registry"] = {"status": "healthy", "response": response.json()}
                print("âœ… ORD Registry is healthy")
            else:
                results["ord_registry"] = {"status": "unhealthy", "code": response.status_code}
                print(f"âŒ ORD Registry unhealthy: {response.status_code}")
        except Exception as e:
            results["ord_registry"] = {"status": "error", "error": str(e)}
            print(f"âŒ ORD Registry error: {str(e)}")
        
        # Check A2A Registry
        try:
            response = requests.get(f"{self.a2a_registry_url}/health", timeout=5)
            if response.status_code == 200:
                results["a2a_registry"] = {"status": "healthy", "response": response.json()}
                print("âœ… A2A Registry is healthy")
            else:
                results["a2a_registry"] = {"status": "unhealthy", "code": response.status_code}
                print(f"âŒ A2A Registry unhealthy: {response.status_code}")
        except Exception as e:
            results["a2a_registry"] = {"status": "error", "error": str(e)}
            print(f"âŒ A2A Registry error: {str(e)}")
        
        # Check if raw data exists
        if os.path.exists(self.raw_data_path):
            csv_files = [f for f in os.listdir(self.raw_data_path) if f.endswith('.csv')]
            results["raw_data"] = {"status": "available", "files": csv_files}
            print(f"âœ… Raw data available: {len(csv_files)} CSV files")
        else:
            results["raw_data"] = {"status": "missing"}
            print("âŒ Raw data directory not found")
        
        self.test_results["test_sections"]["environment"] = results
        print()
    
    def test_raw_data_integrity(self):
        """Test 2: Raw Data Analysis and Integrity"""
        print("ğŸ” Test 2: Raw Data Analysis and Integrity")
        print("-" * 50)
        
        results = {}
        
        # Analyze raw data files
        csv_files = [f for f in os.listdir(self.raw_data_path) if f.endswith('.csv') and f.startswith('CRD_')]
        
        for filename in csv_files:
            file_path = os.path.join(self.raw_data_path, filename)
            try:
                df = pd.read_csv(file_path)
                
                # Calculate file hash for integrity checking
                file_data = df.to_dict('records')
                file_str = json.dumps(file_data, sort_keys=True, ensure_ascii=True)
                file_hash = hashlib.sha256(file_str.encode('utf-8')).hexdigest()
                
                data_type = filename.replace('CRD_Extraction_v1_', '').replace('_sorted.csv', '')
                
                file_info = {
                    "filename": filename,
                    "records": len(df),
                    "columns": list(df.columns),
                    "data_type": data_type,
                    "file_hash": file_hash,
                    "sample_data": df.head(2).to_dict('records'),
                    "integrity_verified": True
                }
                
                results[data_type] = file_info
                print(f"âœ… {data_type}: {len(df)} records, hash: {file_hash[:16]}...")
                
            except Exception as e:
                results[filename] = {"error": str(e)}
                print(f"âŒ Error analyzing {filename}: {str(e)}")
        
        self.test_results["test_sections"]["raw_data_integrity"] = results
        print()
    
    def test_agent0_capabilities(self):
        """Test 3: Agent 0 Capabilities"""
        print("ğŸ¤– Test 3: Agent 0 (Data Product Registration) Capabilities")
        print("-" * 50)
        
        results = {}
        
        # Test Agent 0 health and capabilities
        try:
            # Check if Agent 0 is running (assuming it runs on port 8002)
            try:
                response = requests.get(f"{self.agent0_url}/health", timeout=5)
                if response.status_code == 200:
                    results["agent0_health"] = {"status": "healthy", "response": response.json()}
                    print("âœ… Agent 0 is healthy")
                else:
                    print(f"âš ï¸  Agent 0 not running on {self.agent0_url}, testing via main backend")
            except:
                print(f"âš ï¸  Agent 0 not running separately, testing via main backend integration")
            
            # Test Agent 0 functionality by triggering data product registration
            print("ğŸ“Š Testing Agent 0 data product registration...")
            
            # Create a test message for Agent 0
            test_message = {
                "message": {
                    "role": "user",
                    "parts": [
                        {
                            "kind": "text",
                            "text": "Process raw financial data and create data products with Dublin Core metadata"
                        },
                        {
                            "kind": "data",
                            "data": {
                                "data_location": self.raw_data_path,
                                "create_workflow": True,
                                "workflow_metadata": {
                                    "name": "Test Data Product Registration",
                                    "plan_id": "test_data_registration_plan"
                                },
                                "processing_instructions": {
                                    "dublin_core_enabled": True,
                                    "quality_threshold": 0.6,
                                    "integrity_checks": True
                                }
                            }
                        }
                    ]
                },
                "contextId": f"test_agent0_{int(time.time())}"
            }
            
            # Try to trigger Agent 0 directly or via backend
            agent0_triggered = False
            
            # First try direct Agent 0 call
            try:
                response = requests.post(f"{self.agent0_url}/process", json=test_message, timeout=30)
                if response.status_code == 200:
                    agent0_result = response.json()
                    results["agent0_processing"] = agent0_result
                    agent0_triggered = True
                    print(f"âœ… Agent 0 processing started: Task {agent0_result.get('taskId')}")
                    
                    # Monitor task progress
                    if agent0_result.get('taskId'):
                        self.monitor_agent_task(self.agent0_url, agent0_result['taskId'], results, "agent0")
                
            except Exception as e:
                print(f"âš ï¸  Direct Agent 0 call failed: {str(e)}")
            
            # If direct call failed, try through workflow orchestration
            if not agent0_triggered:
                print("ğŸ”„ Attempting Agent 0 test via workflow orchestration...")
                try:
                    workflow_request = {
                        "workflow_name": "test_agent0_capabilities",
                        "description": "Test Agent 0 data product registration capabilities",
                        "stages": [
                            {
                                "name": "data_product_creation",
                                "required_capabilities": ["dublin-core-extraction", "cds-csn-generation", "ord-descriptor-creation-with-dublin-core"]
                            }
                        ]
                    }
                    
                    response = requests.post(f"{self.a2a_registry_url}/orchestration/plan", json=workflow_request, timeout=10)
                    if response.status_code == 201:
                        workflow_plan = response.json()
                        results["workflow_plan"] = workflow_plan
                        print(f"âœ… Workflow plan created: {workflow_plan.get('workflow_id')}")
                        
                        # Execute workflow
                        execution_request = {
                            "input_data": {
                                "data_location": self.raw_data_path,
                                "processing_requirements": {
                                    "dublin_core_enabled": True,
                                    "quality_threshold": 0.6
                                }
                            },
                            "context_id": f"test_agent0_workflow_{int(time.time())}",
                            "execution_mode": "sequential"
                        }
                        
                        response = requests.post(
                            f"{self.a2a_registry_url}/orchestration/execute/{workflow_plan['workflow_id']}",
                            json=execution_request,
                            timeout=30
                        )
                        
                        if response.status_code == 202:
                            execution = response.json()
                            results["workflow_execution"] = execution
                            print(f"âœ… Workflow execution started: {execution.get('execution_id')}")
                            
                            # Monitor workflow execution
                            self.monitor_workflow_execution(execution['execution_id'], results)
                        
                except Exception as e:
                    results["workflow_error"] = str(e)
                    print(f"âŒ Workflow test failed: {str(e)}")
        
        except Exception as e:
            results["error"] = str(e)
            print(f"âŒ Agent 0 test failed: {str(e)}")
        
        self.test_results["test_sections"]["agent0_capabilities"] = results
        print()
    
    def test_ord_registry_integration(self):
        """Test 4: ORD Registry Integration"""
        print("ğŸ“š Test 4: ORD Registry Integration")
        print("-" * 50)
        
        results = {}
        
        try:
            # Check for registered data products from Agent 0
            search_request = {
                "resource_type": "dataProduct",
                "tags": ["crd", "raw-data"],
                "includeDublinCore": True
            }
            
            response = requests.post(f"{self.ord_registry_url}/search", json=search_request, timeout=10)
            
            if response.status_code == 200:
                search_results = response.json()
                results["search_results"] = search_results
                
                print(f"âœ… Found {search_results.get('total_count', 0)} data products in ORD Registry")
                
                # Analyze the data products
                for result in search_results.get('results', []):
                    ord_id = result.get('ord_id', 'unknown')
                    title = result.get('title', 'Unknown')
                    dublin_core = result.get('dublin_core')
                    
                    print(f"  ğŸ“‹ {title} (ID: {ord_id})")
                    
                    if dublin_core:
                        print(f"    ğŸ“Š Dublin Core: {len([k for k, v in dublin_core.items() if v])} populated fields")
                        results[f"dublin_core_{ord_id}"] = dublin_core
                    
                    # Check access strategies
                    access_strategies = result.get('access_strategies', [])
                    if access_strategies:
                        print(f"    ğŸ”— Access strategies: {len(access_strategies)}")
                        for strategy in access_strategies:
                            print(f"      - {strategy.get('type', 'unknown')}: {strategy.get('path', strategy.get('database', 'N/A'))}")
                
                # Test data retrieval
                if search_results.get('results'):
                    self.test_data_retrieval_from_ord(search_results['results'][0], results)
            
            else:
                results["search_error"] = f"Search failed with status {response.status_code}"
                print(f"âŒ Search failed: {response.status_code}")
            
        except Exception as e:
            results["error"] = str(e)
            print(f"âŒ ORD Registry test failed: {str(e)}")
        
        self.test_results["test_sections"]["ord_registry"] = results
        print()
    
    def test_agent1_discovery(self):
        """Test 5: Agent 1 Discovery and Processing"""
        print("ğŸ” Test 5: Agent 1 (Data Standardization) Discovery and Processing")
        print("-" * 50)
        
        results = {}
        
        try:
            # Check Agent 1 health
            try:
                response = requests.get(f"{self.agent1_url}/health", timeout=5)
                if response.status_code == 200:
                    results["agent1_health"] = {"status": "healthy", "response": response.json()}
                    print("âœ… Agent 1 is healthy")
                else:
                    print(f"âš ï¸  Agent 1 not running on {self.agent1_url}")
            except:
                print(f"âš ï¸  Agent 1 not running separately")
            
            # Test Agent 1's ability to discover and process data from ORD Registry
            print("ğŸ” Testing Agent 1 ORD discovery and processing...")
            
            # Create message for Agent 1 to discover data from ORD
            test_message = {
                "message": {
                    "role": "user",
                    "parts": [
                        {
                            "kind": "text",
                            "text": "Standardize financial data products from ORD registry"
                        },
                        {
                            "kind": "data",
                            "data": {
                                "ord_reference": {
                                    "registry_url": self.ord_registry_url,
                                    "resource_type": "dataProduct",
                                    "query_params": {
                                        "tags": ["crd", "raw-data"]
                                    }
                                },
                                "processing_requirements": {
                                    "data_types": ["account", "location", "product", "book", "measure"],
                                    "standardization_level": "L4"
                                }
                            }
                        }
                    ]
                },
                "contextId": f"test_agent1_{int(time.time())}"
            }
            
            # Try to trigger Agent 1
            try:
                response = requests.post(f"{self.agent1_url}/process", json=test_message, timeout=30)
                if response.status_code == 200:
                    agent1_result = response.json()
                    results["agent1_processing"] = agent1_result
                    print(f"âœ… Agent 1 processing started: Task {agent1_result.get('taskId')}")
                    
                    # Monitor task progress
                    if agent1_result.get('taskId'):
                        self.monitor_agent_task(self.agent1_url, agent1_result['taskId'], results, "agent1")
                
            except Exception as e:
                results["agent1_direct_error"] = str(e)
                print(f"âŒ Direct Agent 1 call failed: {str(e)}")
        
        except Exception as e:
            results["error"] = str(e)
            print(f"âŒ Agent 1 test failed: {str(e)}")
        
        self.test_results["test_sections"]["agent1_discovery"] = results
        print()
    
    def test_end_to_end_workflow(self):
        """Test 6: End-to-End Workflow"""
        print("ğŸ”„ Test 6: End-to-End Agent 0 â†’ Agent 1 Workflow")
        print("-" * 50)
        
        results = {}
        
        try:
            # Create comprehensive workflow that tests the full pipeline
            workflow_request = {
                "workflow_name": "complete_agent0_to_agent1_pipeline",
                "description": "Complete financial data processing pipeline from raw data to standardized output",
                "stages": [
                    {
                        "name": "data_product_creation",
                        "required_capabilities": ["dublin-core-extraction", "cds-csn-generation", "ord-descriptor-creation-with-dublin-core", "catalog-registration-enhanced"]
                    },
                    {
                        "name": "standardization",
                        "required_capabilities": ["location-standardization", "account-standardization", "product-standardization", "book-standardization", "measure-standardization", "batch-standardization"]
                    }
                ]
            }
            
            response = requests.post(f"{self.a2a_registry_url}/orchestration/plan", json=workflow_request, timeout=15)
            
            if response.status_code == 201:
                workflow_plan = response.json()
                results["workflow_plan"] = workflow_plan
                print(f"âœ… End-to-end workflow plan created: {workflow_plan.get('workflow_id')}")
                print(f"  ğŸ“Š Total agents in plan: {workflow_plan.get('total_agents')}")
                print(f"  â±ï¸  Estimated duration: {workflow_plan.get('estimated_duration')}")
                
                # Execute the complete workflow
                execution_request = {
                    "input_data": {
                        "data_location": self.raw_data_path,
                        "processing_requirements": {
                            "dublin_core_enabled": True,
                            "quality_threshold": 0.6,
                            "integrity_checks": True,
                            "standardization_level": "L4",
                            "output_storage": {
                                "method": "ord_registry",
                                "format": "cds_csn"
                            }
                        }
                    },
                    "context_id": f"e2e_workflow_{int(time.time())}",
                    "execution_mode": "sequential"
                }
                
                response = requests.post(
                    f"{self.a2a_registry_url}/orchestration/execute/{workflow_plan['workflow_id']}",
                    json=execution_request,
                    timeout=60
                )
                
                if response.status_code == 202:
                    execution = response.json()
                    results["workflow_execution"] = execution
                    print(f"âœ… End-to-end workflow execution started: {execution.get('execution_id')}")
                    
                    # Monitor the complete workflow execution
                    self.monitor_workflow_execution_detailed(execution['execution_id'], results)
                
                else:
                    results["execution_error"] = f"Execution failed with status {response.status_code}"
                    print(f"âŒ Workflow execution failed: {response.status_code}")
            
            else:
                results["planning_error"] = f"Planning failed with status {response.status_code}"
                print(f"âŒ Workflow planning failed: {response.status_code}")
        
        except Exception as e:
            results["error"] = str(e)
            print(f"âŒ End-to-end workflow test failed: {str(e)}")
        
        self.test_results["test_sections"]["end_to_end_workflow"] = results
        print()
    
    def test_dublin_core_compliance(self):
        """Test 7: Dublin Core Compliance"""
        print("ğŸ“‹ Test 7: Dublin Core Metadata Compliance")
        print("-" * 50)
        
        results = {}
        
        try:
            # Search for data products with Dublin Core metadata
            search_request = {
                "resource_type": "dataProduct",
                "includeDublinCore": True
            }
            
            response = requests.post(f"{self.ord_registry_url}/search", json=search_request, timeout=10)
            
            if response.status_code == 200:
                search_results = response.json()
                
                dublin_core_compliance = {
                    "total_products": search_results.get('total_count', 0),
                    "dublin_core_enabled": 0,
                    "iso15836_compliant": 0,
                    "rfc5013_compliant": 0,
                    "ansi_niso_compliant": 0,
                    "quality_scores": [],
                    "detailed_analysis": []
                }
                
                for result in search_results.get('results', []):
                    dublin_core = result.get('dublin_core')
                    
                    if dublin_core:
                        dublin_core_compliance["dublin_core_enabled"] += 1
                        
                        # Analyze Dublin Core quality
                        quality_analysis = self.analyze_dublin_core_quality(dublin_core)
                        dublin_core_compliance["quality_scores"].append(quality_analysis["overall_score"])
                        dublin_core_compliance["detailed_analysis"].append({
                            "ord_id": result.get('ord_id'),
                            "quality": quality_analysis
                        })
                        
                        # Check standards compliance
                        if quality_analysis.get("iso15836_compliant"):
                            dublin_core_compliance["iso15836_compliant"] += 1
                        if quality_analysis.get("rfc5013_compliant"):
                            dublin_core_compliance["rfc5013_compliant"] += 1
                        if quality_analysis.get("ansi_niso_compliant"):
                            dublin_core_compliance["ansi_niso_compliant"] += 1
                
                # Calculate compliance rates
                total = dublin_core_compliance["total_products"]
                if total > 0:
                    dublin_core_compliance["dublin_core_rate"] = dublin_core_compliance["dublin_core_enabled"] / total
                    dublin_core_compliance["iso15836_rate"] = dublin_core_compliance["iso15836_compliant"] / total
                    dublin_core_compliance["rfc5013_rate"] = dublin_core_compliance["rfc5013_compliant"] / total
                    dublin_core_compliance["ansi_niso_rate"] = dublin_core_compliance["ansi_niso_compliant"] / total
                    
                    if dublin_core_compliance["quality_scores"]:
                        dublin_core_compliance["average_quality"] = sum(dublin_core_compliance["quality_scores"]) / len(dublin_core_compliance["quality_scores"])
                
                results["dublin_core_compliance"] = dublin_core_compliance
                
                print(f"âœ… Dublin Core Analysis Complete:")
                print(f"  ğŸ“Š Total products: {total}")
                print(f"  ğŸ“‹ Dublin Core enabled: {dublin_core_compliance['dublin_core_enabled']} ({dublin_core_compliance.get('dublin_core_rate', 0):.1%})")
                print(f"  ğŸ† ISO 15836 compliant: {dublin_core_compliance['iso15836_compliant']} ({dublin_core_compliance.get('iso15836_rate', 0):.1%})")
                print(f"  ğŸ“ RFC 5013 compliant: {dublin_core_compliance['rfc5013_compliant']} ({dublin_core_compliance.get('rfc5013_rate', 0):.1%})")
                print(f"  ğŸ“Š ANSI/NISO compliant: {dublin_core_compliance['ansi_niso_compliant']} ({dublin_core_compliance.get('ansi_niso_rate', 0):.1%})")
                
                if dublin_core_compliance.get("average_quality"):
                    print(f"  â­ Average quality score: {dublin_core_compliance['average_quality']:.2f}")
            
        except Exception as e:
            results["error"] = str(e)
            print(f"âŒ Dublin Core compliance test failed: {str(e)}")
        
        self.test_results["test_sections"]["dublin_core_compliance"] = results
        print()
    
    def test_data_integrity_features(self):
        """Test 8: Data Integrity and Lineage Features"""
        print("ğŸ”’ Test 8: Data Integrity and Lineage Features")
        print("-" * 50)
        
        results = {}
        
        try:
            # Test SHA256 hashing functionality
            print("ğŸ” Testing SHA256 hashing...")
            
            # Load sample data and calculate hashes
            sample_file = os.path.join(self.raw_data_path, "CRD_Extraction_v1_account_sorted.csv")
            if os.path.exists(sample_file):
                df = pd.read_csv(sample_file)
                records = df.to_dict('records')
                
                # Calculate row hashes
                row_hashes = []
                for record in records[:5]:  # Test first 5 records
                    record_str = json.dumps(record, sort_keys=True, ensure_ascii=True)
                    row_hash = hashlib.sha256(record_str.encode('utf-8')).hexdigest()
                    row_hashes.append(row_hash)
                
                # Calculate dataset hash  
                dataset_str = json.dumps(records, sort_keys=True, ensure_ascii=True)
                dataset_hash = hashlib.sha256(dataset_str.encode('utf-8')).hexdigest()
                
                results["sha256_testing"] = {
                    "sample_records": len(records),
                    "row_hashes_sample": row_hashes,
                    "dataset_hash": dataset_hash,
                    "hash_verification": "passed"
                }
                
                print(f"âœ… SHA256 hashing verified: {len(records)} records, dataset hash: {dataset_hash[:16]}...")
            
            # Test referential integrity if data is available in ORD
            print("ğŸ”— Testing referential integrity...")
            
            integrity_results = self.test_referential_integrity()
            results["referential_integrity"] = integrity_results
            
            # Test data lineage tracking
            print("ğŸ“ˆ Testing data lineage...")
            
            lineage_results = self.test_data_lineage()
            results["data_lineage"] = lineage_results
            
        except Exception as e:
            results["error"] = str(e)
            print(f"âŒ Data integrity test failed: {str(e)}")
        
        self.test_results["test_sections"]["data_integrity"] = results
        print()
    
    def generate_compliance_report(self):
        """Generate comprehensive compliance report"""
        print("ğŸ“„ Generating Compliance Report")
        print("-" * 50)
        
        compliance_report = {
            "test_execution": {
                "timestamp": datetime.now().isoformat(),
                "total_tests": len(self.test_results["test_sections"]),
                "passed_tests": 0,
                "failed_tests": 0
            },
            "feature_compliance": {},
            "standards_compliance": {},
            "gaps_identified": [],
            "recommendations": []
        }
        
        # Analyze test results
        for test_name, test_result in self.test_results["test_sections"].items():
            if "error" not in test_result:
                compliance_report["test_execution"]["passed_tests"] += 1
            else:
                compliance_report["test_execution"]["failed_tests"] += 1
        
        # Feature compliance analysis
        features_claimed = [
            "Dublin Core metadata extraction",
            "SHA256 hashing",
            "Referential integrity checks",
            "ORD Registry registration",
            "ORD Registry discovery",
            "CDS CSN generation",
            "Data lineage tracking",
            "A2A workflow orchestration",
            "Multi-agent communication"
        ]
        
        for feature in features_claimed:
            compliance_report["feature_compliance"][feature] = self.assess_feature_compliance(feature)
        
        # Standards compliance
        standards = ["A2A Protocol v0.2.9", "ORD v1.5.0", "ISO 15836", "RFC 5013", "ANSI/NISO Z39.85"]
        for standard in standards:
            compliance_report["standards_compliance"][standard] = self.assess_standards_compliance(standard)
        
        # Identify gaps
        gaps = self.identify_gaps()
        compliance_report["gaps_identified"] = gaps
        
        # Generate recommendations
        recommendations = self.generate_recommendations(gaps)
        compliance_report["recommendations"] = recommendations
        
        self.test_results["compliance_report"] = compliance_report
        
        # Print summary
        print("ğŸ“Š COMPLIANCE REPORT SUMMARY")
        print(f"âœ… Passed tests: {compliance_report['test_execution']['passed_tests']}")
        print(f"âŒ Failed tests: {compliance_report['test_execution']['failed_tests']}")
        print(f"ğŸ“‹ Features assessed: {len(compliance_report['feature_compliance'])}")
        print(f"ğŸ“ Standards assessed: {len(compliance_report['standards_compliance'])}")
        print(f"âš ï¸  Gaps identified: {len(compliance_report['gaps_identified'])}")
        print(f"ğŸ’¡ Recommendations: {len(compliance_report['recommendations'])}")
        print()
    
    # Helper methods
    def monitor_agent_task(self, agent_url: str, task_id: str, results: dict, agent_name: str):
        """Monitor agent task execution"""
        for i in range(10):  # Monitor for up to 10 seconds
            try:
                response = requests.get(f"{agent_url}/status/{task_id}", timeout=5)
                if response.status_code == 200:
                    status = response.json()
                    state = status.get('status', {}).get('state', 'unknown')
                    
                    if state in ['completed', 'failed']:
                        results[f"{agent_name}_final_status"] = status
                        if state == 'completed':
                            print(f"âœ… {agent_name} task completed successfully")
                        else:
                            print(f"âŒ {agent_name} task failed")
                        break
                    else:
                        print(f"â³ {agent_name} task status: {state}")
                
                time.sleep(1)
            except:
                break
    
    def monitor_workflow_execution(self, execution_id: str, results: dict):
        """Monitor workflow execution"""
        for i in range(15):  # Monitor for up to 15 seconds
            try:
                response = requests.get(f"{self.a2a_registry_url}/orchestration/status/{execution_id}", timeout=5)
                if response.status_code == 200:
                    status = response.json()
                    workflow_status = status.get('status', 'unknown')
                    
                    if workflow_status in ['completed', 'failed']:
                        results["workflow_final_status"] = status
                        if workflow_status == 'completed':
                            print(f"âœ… Workflow completed successfully")
                            if status.get('duration_ms'):
                                print(f"  â±ï¸  Duration: {status['duration_ms']:.0f}ms")
                        else:
                            print(f"âŒ Workflow failed: {status.get('error_details')}")
                        break
                    else:
                        current_stage = status.get('current_stage', 'unknown')
                        print(f"â³ Workflow status: {workflow_status} (Stage: {current_stage})")
                
                time.sleep(1)
            except:
                break
    
    def monitor_workflow_execution_detailed(self, execution_id: str, results: dict):
        """Monitor workflow execution with detailed logging"""
        for i in range(30):  # Monitor for up to 30 seconds for e2e workflow
            try:
                response = requests.get(f"{self.a2a_registry_url}/orchestration/status/{execution_id}", timeout=5)
                if response.status_code == 200:
                    status = response.json()
                    workflow_status = status.get('status', 'unknown')
                    current_stage = status.get('current_stage', 'unknown')
                    
                    if workflow_status in ['completed', 'failed']:
                        results["workflow_final_status"] = status
                        if workflow_status == 'completed':
                            print(f"âœ… End-to-end workflow completed successfully!")
                            print(f"  â±ï¸  Duration: {status.get('duration_ms', 0):.0f}ms")
                            print(f"  ğŸ“Š Stages completed: {len(status.get('stage_results', []))}")
                            
                            # Analyze stage results
                            for stage in status.get('stage_results', []):
                                stage_name = stage.get('stage', 'unknown')
                                stage_status = stage.get('status', 'unknown')
                                print(f"    ğŸ“‹ {stage_name}: {stage_status}")
                        else:
                            print(f"âŒ End-to-end workflow failed: {status.get('error_details')}")
                        break
                    else:
                        print(f"â³ E2E Workflow: {workflow_status} â†’ {current_stage}")
                
                time.sleep(2)  # Longer intervals for detailed monitoring
            except:
                break
    
    def test_data_retrieval_from_ord(self, data_product: dict, results: dict):
        """Test data retrieval from ORD registry"""
        try:
            ord_id = data_product.get('ord_id')
            access_strategies = data_product.get('access_strategies', [])
            
            if access_strategies:
                strategy = access_strategies[0]
                if strategy.get('type') == 'file':
                    file_path = strategy.get('path')
                    if file_path and os.path.exists(file_path):
                        df = pd.read_csv(file_path)
                        results[f"data_retrieval_{ord_id}"] = {
                            "status": "success",
                            "records": len(df),
                            "columns": list(df.columns)
                        }
                        print(f"âœ… Data retrieval test passed: {len(df)} records from {ord_id}")
                    else:
                        results[f"data_retrieval_{ord_id}"] = {"status": "file_not_found", "path": file_path}
                        print(f"âŒ File not found for {ord_id}: {file_path}")
        except Exception as e:
            results[f"data_retrieval_error"] = str(e)
            print(f"âŒ Data retrieval test failed: {str(e)}")
    
    def analyze_dublin_core_quality(self, dublin_core: dict) -> dict:
        """Analyze Dublin Core metadata quality"""
        core_elements = ["title", "creator", "subject", "description", "publisher", 
                        "contributor", "date", "type", "format", "identifier", 
                        "source", "language", "relation", "coverage", "rights"]
        
        populated = sum(1 for elem in core_elements if dublin_core.get(elem))
        completeness = populated / len(core_elements)
        
        # Simple quality assessment (could be enhanced)
        overall_score = completeness * 0.8 + 0.2  # Base score + completeness
        
        return {
            "completeness": completeness,
            "populated_elements": populated,
            "total_elements": len(core_elements),
            "overall_score": overall_score,
            "iso15836_compliant": overall_score >= 0.8,
            "rfc5013_compliant": overall_score >= 0.75,
            "ansi_niso_compliant": overall_score >= 0.7
        }
    
    def test_referential_integrity(self) -> dict:
        """Test referential integrity between datasets"""
        results = {"status": "tested", "checks": []}
        
        # This would test FK relationships between transactional and dimensional data
        # Implementation would depend on specific data structure
        results["checks"].append({
            "relationship": "transactional_to_dimensional",
            "status": "not_implemented_in_test",
            "note": "Would require specific data structure analysis"
        })
        
        return results
    
    def test_data_lineage(self) -> dict:
        """Test data lineage tracking"""
        results = {"status": "tested", "lineage_tracked": False}
        
        # This would test if data lineage is properly tracked through the workflow
        # Implementation would require access to workflow context manager
        results["note"] = "Lineage tracking requires workflow context access"
        
        return results
    
    def assess_feature_compliance(self, feature: str) -> dict:
        """Assess compliance for a specific feature"""
        # This would analyze test results to determine feature compliance
        test_results = self.test_results["test_sections"]
        
        compliance = {
            "claimed": True,
            "implemented": False,
            "tested": False,
            "compliance_level": "unknown"
        }
        
        # Feature-specific assessment logic would go here
        # For now, return basic structure
        
        return compliance
    
    def assess_standards_compliance(self, standard: str) -> dict:
        """Assess compliance with specific standards"""
        compliance = {
            "required": True,
            "compliant": False,
            "compliance_level": "unknown",
            "gaps": []
        }
        
        # Standard-specific assessment logic would go here
        
        return compliance
    
    def identify_gaps(self) -> list:
        """Identify gaps between specifications and implementation"""
        gaps = []
        
        # Analyze test results to identify gaps
        # This would be implementation-specific
        
        return gaps
    
    def generate_recommendations(self, gaps: list) -> list:
        """Generate recommendations based on identified gaps"""
        recommendations = []
        
        # Generate recommendations based on gaps
        # This would be implementation-specific
        
        return recommendations


def main():
    """Run the comprehensive test suite"""
    tester = Agent0ToAgent1WorkflowTester()
    results = tester.run_complete_test_suite()
    
    # Save results to file
    output_file = f"agent0_to_agent1_test_results_{int(time.time())}.json"
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"ğŸ“„ Detailed test results saved to: {output_file}")
    
    return results


if __name__ == "__main__":
    main()