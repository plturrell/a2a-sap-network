"""
{{ description }}
Generated by Agent Builder Agent on {{ generated_at }}
"""

import asyncio
import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from uuid import uuid4
import logging
import time

from app.a2a.sdk import (
    A2AAgentBase, a2a_handler, a2a_skill, a2a_task,
    A2AMessage, MessageRole, create_agent_id
)
from app.a2a.sdk.utils import create_success_response, create_error_response
from app.a2a.core.workflowContext import workflowContextManager
from app.a2a.core.workflowMonitor import workflowMonitor
from prometheus_client import Counter, Histogram, Gauge, start_http_server

# Integration specific dependencies
import httpx
import aiohttp
from urllib.parse import urljoin, urlparse
from pydantic import BaseModel, ValidationError

logger = logging.getLogger(__name__)


class {{ agent_name.replace(' ', '').replace('_', '') }}SDK(A2AAgentBase):
    """
    {{ agent_name }} - SDK Version
    {{ description }}
    """
    
    def __init__(self, base_url: str, **kwargs):
        super().__init__(
            agent_id="{{ agent_id }}",
            name="{{ agent_name }}",
            description="{{ description }}",
            version="1.0.0",
            base_url=base_url
        )
        
        # Configuration
        {% for key, value in configuration.items() %}
        self.{{ key }} = {{ value|tojson if value is string else value|tojson }}
        {% endfor %}
        
        # Integration configuration
        self.max_retries = kwargs.get('max_retries', {{ max_retries|default(3) }})
        self.timeout = kwargs.get('timeout', {{ timeout|default(30) }})
        self.connection_pool_size = kwargs.get('connection_pool_size', 100)
        
        # HTTP clients
        self.http_client = None
        self.aiohttp_session = None
        
        # Connection registry
        self.registered_endpoints = {}
        self.webhook_handlers = {}
        
        # Prometheus metrics
        self.tasks_completed = Counter('a2a_agent_tasks_completed_total', 'Total completed tasks', ['agent_id', 'task_type'])
        self.tasks_failed = Counter('a2a_agent_tasks_failed_total', 'Total failed tasks', ['agent_id', 'task_type'])
        self.processing_time = Histogram('a2a_agent_processing_time_seconds', 'Task processing time', ['agent_id', 'task_type'])
        self.queue_depth = Gauge('a2a_agent_queue_depth', 'Current queue depth', ['agent_id'])
        self.skills_count = Gauge('a2a_agent_skills_count', 'Number of skills available', ['agent_id'])
        self.api_requests = Counter('a2a_agent_api_requests_total', 'Total API requests', ['agent_id', 'endpoint', 'method', 'status'])
        self.webhook_events = Counter('a2a_agent_webhook_events_total', 'Total webhook events', ['agent_id', 'event_type'])
        
        # Set initial metrics
        self.queue_depth.labels(agent_id=self.agent_id).set(0)
        self.skills_count.labels(agent_id=self.agent_id).set({{ skills|length }})
        
        # Start metrics server
        self._start_metrics_server()
        
        self.processing_stats = {
            "total_processed": 0,
            "api_calls_made": 0,
            "webhooks_processed": 0,
            "data_synced": 0,
            {% for skill in skills %}
            "{{ skill }}_count": 0,
            {% endfor %}
        }
        
        logger.info(f"Initialized {self.name} with SDK v1.0.0")
    
    def _start_metrics_server(self):
        """Start Prometheus metrics server"""
        try:
            port = int(os.environ.get('PROMETHEUS_PORT', '8000'))
            start_http_server(port)
            logger.info(f"Started Prometheus metrics server on port {port}")
        except Exception as e:
            logger.warning(f"Failed to start metrics server: {e}")
    
    async def initialize(self) -> None:
        """Initialize agent resources"""
        logger.info("Initializing {{ agent_name }}...")
        
        # Initialize storage
        storage_path = os.getenv("AGENT_STORAGE_PATH", "/tmp/{{ agent_id }}_state")
        os.makedirs(storage_path, exist_ok=True)
        self.storage_path = storage_path
        
        # Initialize HTTP clients
        await self._initialize_http_clients()
        
        # Custom initialization logic
        await self._custom_initialization()
        
        logger.info("{{ agent_name }} initialization complete")
    
    async def _initialize_http_clients(self):
        """Initialize HTTP clients for API integrations"""
        # Initialize HTTPX client
        self.http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(self.timeout),
            limits=httpx.Limits(max_connections=self.connection_pool_size)
        )
        
        # Initialize aiohttp session
        timeout = aiohttp.ClientTimeout(total=self.timeout)
        connector = aiohttp.TCPConnector(limit=self.connection_pool_size)
        self.aiohttp_session = aiohttp.ClientSession(
            timeout=timeout,
            connector=connector
        )
        
        logger.info("HTTP clients initialized successfully")
    
    async def _custom_initialization(self):
        """Custom initialization logic for integration"""
        # Load registered endpoints
        endpoints_file = os.path.join(self.storage_path, "endpoints.json")
        if os.path.exists(endpoints_file):
            with open(endpoints_file, 'r') as f:
                self.registered_endpoints = json.load(f)
                logger.info(f"Loaded {len(self.registered_endpoints)} registered endpoints")

{% for handler in handlers %}
    @a2a_handler("{{ handler }}")
    async def handle_{{ handler }}(self, message: A2AMessage) -> Dict[str, Any]:
        """Handler for {{ handler }} requests"""
        start_time = time.time()
        
        try:
            # Extract request data
            request_data = self._extract_request_data(message)
            
            # Process request - implement your logic here
            result = await self._process_{{ handler }}(request_data, message.conversation_id)
            
            # Record success metrics
            self.tasks_completed.labels(agent_id=self.agent_id, task_type='{{ handler }}').inc()
            self.processing_time.labels(agent_id=self.agent_id, task_type='{{ handler }}').observe(time.time() - start_time)
            
            return create_success_response(result)
            
        except Exception as e:
            # Record failure metrics
            self.tasks_failed.labels(agent_id=self.agent_id, task_type='{{ handler }}').inc()
            logger.error(f"{{ handler }} failed: {e}")
            return create_error_response(f"{{ handler }} failed: {str(e)}")
    
    async def _process_{{ handler }}(self, request_data: Dict[str, Any], context_id: str) -> Dict[str, Any]:
        """Process {{ handler }} request - implement your logic here"""
        {% if handler == 'external_api' %}
        # External API specific implementation
        api_config = request_data.get('api_config', {})
        endpoint = api_config.get('endpoint')
        method = api_config.get('method', 'GET')
        data = request_data.get('data')
        headers = api_config.get('headers', {})
        
        if not endpoint:
            raise ValueError("API endpoint is required for external API calls")
        
        # Make API call
        api_response = await self._make_api_call(
            endpoint=endpoint,
            method=method,
            data=data,
            headers=headers,
            context_id=context_id
        )
        
        self.processing_stats["api_calls_made"] += 1
        
        return {
            "message": "{{ handler }} completed successfully",
            "context_id": context_id,
            "endpoint": endpoint,
            "method": method,
            "response": api_response,
            "processing_time": time.time() - start_time
        }
        
        {% elif handler == 'webhook_handler' %}
        # Webhook handler specific implementation
        webhook_data = request_data.get('webhook_data')
        event_type = request_data.get('event_type')
        source = request_data.get('source')
        
        if not webhook_data or not event_type:
            raise ValueError("webhook_data and event_type are required for webhook processing")
        
        # Process webhook
        processing_result = await self._process_webhook(
            webhook_data=webhook_data,
            event_type=event_type,
            source=source,
            context_id=context_id
        )
        
        # Update metrics
        self.webhook_events.labels(agent_id=self.agent_id, event_type=event_type).inc()
        self.processing_stats["webhooks_processed"] += 1
        
        return {
            "message": "{{ handler }} completed successfully",
            "context_id": context_id,
            "event_type": event_type,
            "source": source,
            "processing_result": processing_result,
            "processing_time": time.time() - start_time
        }
        
        {% else %}
        # Generic handler implementation
        return {"message": "{{ handler }} processed successfully", "context_id": context_id}
        {% endif %}

{% endfor %}

{% for skill in skills %}
    @a2a_skill("{{ skill }}")
    async def {{ skill }}_skill(self, *args, **kwargs) -> Dict[str, Any]:
        """{{ skill }} skill implementation"""
        
        {% if skill == 'api_client' %}
        # API client implementation
        endpoint = kwargs.get('endpoint')
        method = kwargs.get('method', 'GET')
        data = kwargs.get('data')
        headers = kwargs.get('headers', {})
        params = kwargs.get('params', {})
        
        if not endpoint:
            raise ValueError("Endpoint is required for API client")
        
        # Make HTTP request
        response = await self._make_http_request(
            endpoint=endpoint,
            method=method,
            data=data,
            headers=headers,
            params=params
        )
        
        self.processing_stats["{{ skill }}_count"] += 1
        
        return {
            "response": response,
            "endpoint": endpoint,
            "method": method,
            "status_code": response.get('status_code'),
            "timestamp": datetime.now().isoformat()
        }
        
        {% elif skill == 'data_mapping' %}
        # Data mapping implementation
        source_data = kwargs.get('source_data')
        mapping_config = kwargs.get('mapping_config', {})
        
        if source_data is None:
            raise ValueError("Source data is required for data mapping")
        
        # Apply data mapping
        mapped_data = await self._apply_data_mapping(source_data, mapping_config)
        
        self.processing_stats["{{ skill }}_count"] += 1
        
        return {
            "mapped_data": mapped_data,
            "mapping_applied": len(mapping_config),
            "source_fields": len(source_data) if isinstance(source_data, dict) else "unknown",
            "timestamp": datetime.now().isoformat()
        }
        
        {% elif skill == 'protocol_translation' %}
        # Protocol translation implementation
        source_protocol = kwargs.get('source_protocol')
        target_protocol = kwargs.get('target_protocol')
        data = kwargs.get('data')
        translation_config = kwargs.get('config', {})
        
        if not source_protocol or not target_protocol or data is None:
            raise ValueError("source_protocol, target_protocol, and data are required")
        
        # Translate between protocols
        translated_data = await self._translate_protocol(
            data=data,
            source_protocol=source_protocol,
            target_protocol=target_protocol,
            config=translation_config
        )
        
        self.processing_stats["{{ skill }}_count"] += 1
        
        return {
            "translated_data": translated_data,
            "source_protocol": source_protocol,
            "target_protocol": target_protocol,
            "timestamp": datetime.now().isoformat()
        }
        
        {% else %}
        # Generic skill implementation
        self.processing_stats["{{ skill }}_count"] += 1
        return {"result": "{{ skill }} completed", "timestamp": datetime.now().isoformat()}
        {% endif %}

{% endfor %}

{% for task in tasks %}
    @a2a_task(
        task_type="{{ task }}",
        description="{{ task }} task implementation",
        timeout=300,
        retry_attempts=3  # Higher retry for integration tasks
    )
    async def {{ task }}_task(self, *args, **kwargs) -> Dict[str, Any]:
        """{{ task }} task implementation"""
        
        try:
            {% if task == 'sync_data' %}
            # Sync data task implementation
            source_config = kwargs.get('source_config')
            target_config = kwargs.get('target_config')
            sync_config = kwargs.get('sync_config', {})
            
            if not source_config or not target_config:
                raise ValueError("source_config and target_config are required")
            
            # Get data from source
            source_data = await self._get_data_from_source(source_config)
            
            # Transform data if needed
            if 'transformations' in sync_config:
                transformed_data = await self.execute_skill(
                    "data_mapping",
                    source_data=source_data,
                    mapping_config=sync_config['transformations']
                )
                source_data = transformed_data['mapped_data']
            
            # Send data to target
            sync_result = await self._send_data_to_target(source_data, target_config)
            
            self.processing_stats["data_synced"] += 1
            
            result = {
                "source": source_config.get('name', 'unknown'),
                "target": target_config.get('name', 'unknown'),
                "records_synced": sync_result.get('count', 0),
                "sync_result": sync_result
            }
            
            {% elif task == 'call_external_service' %}
            # Call external service task implementation
            service_config = kwargs.get('service_config')
            request_data = kwargs.get('request_data', {})
            
            if not service_config:
                raise ValueError("service_config is required")
            
            # Use API client skill to make the call
            api_result = await self.execute_skill(
                "api_client",
                endpoint=service_config.get('endpoint'),
                method=service_config.get('method', 'POST'),
                data=request_data,
                headers=service_config.get('headers', {})
            )
            
            result = {
                "service": service_config.get('name', 'unknown'),
                "endpoint": service_config.get('endpoint'),
                "response": api_result['response'],
                "status_code": api_result.get('status_code')
            }
            
            {% elif task == 'process_webhook' %}
            # Process webhook task implementation
            webhook_payload = kwargs.get('webhook_payload')
            webhook_config = kwargs.get('webhook_config', {})
            
            if not webhook_payload:
                raise ValueError("webhook_payload is required")
            
            # Parse webhook payload
            parsed_data = await self._parse_webhook_payload(webhook_payload, webhook_config)
            
            # Process webhook data
            processing_result = await self._handle_webhook_event(parsed_data, webhook_config)
            
            result = {
                "event_type": parsed_data.get('event_type'),
                "source": parsed_data.get('source'),
                "processing_result": processing_result,
                "payload_size": len(str(webhook_payload))
            }
            
            {% else %}
            # Generic task implementation
            result = await self._execute_{{ task }}(*args, **kwargs)
            {% endif %}
            
            self.processing_stats["total_processed"] += 1
            
            return {
                "task_successful": True,
                "task": "{{ task }}",
                "result": result
            }
            
        except Exception as e:
            logger.error(f"{{ task }} task failed: {e}")
            return {
                "task_successful": False,
                "task": "{{ task }}",
                "error": str(e)
            }
    
    async def _execute_{{ task }}(self, *args, **kwargs) -> Dict[str, Any]:
        """Execute {{ task }} - implement your logic here"""
        return {"message": "{{ task }} executed successfully"}

{% endfor %}

    # Integration helper methods
    async def _make_http_request(self, endpoint: str, method: str = 'GET', 
                                data: Any = None, headers: Dict[str, str] = None, 
                                params: Dict[str, Any] = None) -> Dict[str, Any]:
        """Make HTTP request with retry logic"""
        headers = headers or {}
        params = params or {}
        
        for attempt in range(self.max_retries):
            try:
                if method.upper() == 'GET':
                    response = await self.http_client.get(endpoint, headers=headers, params=params)
                elif method.upper() == 'POST':
                    response = await self.http_client.post(endpoint, json=data, headers=headers, params=params)
                elif method.upper() == 'PUT':
                    response = await self.http_client.put(endpoint, json=data, headers=headers, params=params)
                elif method.upper() == 'DELETE':
                    response = await self.http_client.delete(endpoint, headers=headers, params=params)
                else:
                    raise ValueError(f"Unsupported HTTP method: {method}")
                
                # Record metrics
                self.api_requests.labels(
                    agent_id=self.agent_id, 
                    endpoint=urlparse(endpoint).netloc,
                    method=method.upper(),
                    status=str(response.status_code)
                ).inc()
                
                return {
                    "status_code": response.status_code,
                    "data": response.json() if response.headers.get("content-type", "").startswith("application/json") else response.text,
                    "headers": dict(response.headers)
                }
                
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise
                logger.warning(f"HTTP request attempt {attempt + 1} failed: {e}")
                await asyncio.sleep(2 ** attempt)  # Exponential backoff
    
    async def _make_api_call(self, endpoint: str, method: str = 'GET', 
                           data: Any = None, headers: Dict[str, str] = None, 
                           context_id: str = None) -> Dict[str, Any]:
        """Make API call with context tracking"""
        return await self._make_http_request(endpoint, method, data, headers)
    
    async def _apply_data_mapping(self, source_data: Dict[str, Any], 
                                 mapping_config: Dict[str, Any]) -> Dict[str, Any]:
        """Apply data mapping transformations"""
        mapped_data = {}
        
        # Field mapping
        field_mappings = mapping_config.get('field_mappings', {})
        for source_field, target_field in field_mappings.items():
            if source_field in source_data:
                mapped_data[target_field] = source_data[source_field]
        
        # Value transformations
        transformations = mapping_config.get('transformations', {})
        for field, transformation in transformations.items():
            if field in mapped_data:
                if transformation['type'] == 'format':
                    mapped_data[field] = transformation['format'].format(mapped_data[field])
                elif transformation['type'] == 'convert':
                    if transformation['target_type'] == 'int':
                        mapped_data[field] = int(mapped_data[field])
                    elif transformation['target_type'] == 'float':
                        mapped_data[field] = float(mapped_data[field])
                    elif transformation['target_type'] == 'str':
                        mapped_data[field] = str(mapped_data[field])
        
        # Default values
        defaults = mapping_config.get('defaults', {})
        for field, default_value in defaults.items():
            if field not in mapped_data:
                mapped_data[field] = default_value
        
        return mapped_data
    
    async def _translate_protocol(self, data: Any, source_protocol: str, 
                                 target_protocol: str, config: Dict[str, Any]) -> Any:
        """Translate data between different protocols"""
        # This is a simplified implementation - extend based on your protocol needs
        
        if source_protocol == 'json' and target_protocol == 'xml':
            # Convert JSON to XML
            return self._json_to_xml(data)
        elif source_protocol == 'xml' and target_protocol == 'json':
            # Convert XML to JSON
            return self._xml_to_json(data)
        elif source_protocol == 'rest' and target_protocol == 'graphql':
            # Convert REST to GraphQL
            return self._rest_to_graphql(data, config)
        else:
            # No translation needed or unsupported
            return data
    
    def _json_to_xml(self, json_data: Dict[str, Any]) -> str:
        """Convert JSON to XML format"""
        # Simplified XML conversion
        def dict_to_xml(d, root_name='root'):
            xml = f"<{root_name}>"
            for key, value in d.items():
                if isinstance(value, dict):
                    xml += dict_to_xml(value, key)
                elif isinstance(value, list):
                    for item in value:
                        xml += dict_to_xml(item if isinstance(item, dict) else {'value': item}, key)
                else:
                    xml += f"<{key}>{value}</{key}>"
            xml += f"</{root_name}>"
            return xml
        
        return dict_to_xml(json_data)
    
    async def _process_webhook(self, webhook_data: Dict[str, Any], event_type: str, 
                              source: str, context_id: str) -> Dict[str, Any]:
        """Process incoming webhook data"""
        processing_result = {
            "processed_at": datetime.now().isoformat(),
            "event_type": event_type,
            "source": source,
            "context_id": context_id
        }
        
        # Custom webhook processing logic based on event type
        if event_type in self.webhook_handlers:
            handler = self.webhook_handlers[event_type]
            processing_result["custom_processing"] = await handler(webhook_data)
        else:
            # Default processing
            processing_result["data"] = webhook_data
            processing_result["default_processing"] = True
        
        return processing_result
    
    def register_webhook_handler(self, event_type: str, handler_func):
        """Register custom webhook handler"""
        self.webhook_handlers[event_type] = handler_func
        logger.info(f"Registered webhook handler for {event_type}")
    
    def _extract_request_data(self, message: A2AMessage) -> Dict[str, Any]:
        """Extract request data from message"""
        request_data = {}
        
        for part in message.parts:
            if part.kind == "data" and part.data:
                request_data.update(part.data)
            elif part.kind == "file" and part.file:
                request_data["file"] = part.file
        
        return request_data
    
    async def cleanup(self) -> None:
        """Cleanup agent resources"""
        try:
            # Close HTTP clients
            if self.http_client:
                await self.http_client.aclose()
            
            if self.aiohttp_session:
                await self.aiohttp_session.close()
            
            # Save registered endpoints
            endpoints_file = os.path.join(self.storage_path, "endpoints.json")
            with open(endpoints_file, 'w') as f:
                json.dump(self.registered_endpoints, f, indent=2)
            
            # Save processing statistics
            stats_file = os.path.join(self.storage_path, "processing_stats.json")
            with open(stats_file, 'w') as f:
                json.dump(self.processing_stats, f, indent=2)
            
            logger.info(f"{{ agent_name }} cleanup completed")
        except Exception as e:
            logger.error(f"Cleanup failed: {e}")